import torch
import torch.nn as nn

class Attention(nn.Module):
    def __init__(self,embed_size,dout_p,head=8):
        super().__init__()
        self.embed_size = embed_size
        self.heads = heads
        self.n_heads = embed_size // heads
        assert self.embed_size % self.heads == 0
        self.Q2d = nn.Linear(embed_size,embed_size)
        self.K2d = nn.Linear(embed_size,embed_size)
        self.V2d = nn.Linear(embed_size,embed_size)
        self.d2O = nn.Linear(embed_size,embed_size)
        self.dropout = nn.Dropout(dout_p)
    def forward(self,Q,K,V,mask=None):
        B , T , embed_size = Q.shape
        Q = self.Q2d(Q)
        K = self.K2d(K)
        V = self.V2d(V)
        Q = Q.reshape(B , T , self.heads, self.n_heads)
        K = K.reshape(B , T , self.heads, self.n_heads)
        V = V.reshape(B , T , self.heads, self.n_heads)
        
        attention = torch.einsum('bqhd,bkhd->bhqk',Q,K)
        if mask is not None:
            mask = mask.unsqueeze(1).unsqueeze(2)
            attention = attention.masked_fill(mask==0,float('-1e20'))
        attention = torch.softmax(attention,dim=-1)
        out = self.dropout(attention)
        return out

class ResidualNetwork(nn.Module):
    def __init__(self,embed_size,dout_p):
        super().__init__()
        self.layerNorm = nn.LayerNorm(embed_size)
        self.dropout = nn.Dropout(dout_p)
    def forward(self,x,sublayer):
        res = self.layerNorm(x)
        res= self.dropout(res)
        x = x + sublayer(res) 
        return x

class EncodingLayer(nn.Module):
    def __init__(self,embed_size.1):
        super().__init__()
        self.residualNetwork = ResidualNetwork(embed_size,dout_p)

        self.attention = Attention(embed_size,dout_p)
        self.feedForward = nn.Sequential(
            nn.Linear(embed_size,2048),
            nn.ReLU(),
            nn.Dropout(dout_p),
            nn.Linear(2048,embed_size)
        )
    def forward(self,x,video_mask):
        x = self.residualNetwork(x,lambda x: self.attention(x,x,x,video_mask))
        x = self.residualNetwork(x,self.feedForward)
        return x

import unittest
from encodingLayer import EncodingLayer

class TestEncodingLayer(unittest.TestCase):
    def test_encoding_layer(self):
        # Create a sample input tensor and video mask
        x = torch.randn(2, 10, 512)
        video_mask = torch.ones(2, 10)
        video_mask[0, 5:] = 0
        video_mask[1, 8:] = 0

        # Initialize the EncodingLayer
        enc = EncodingLayer(512, 0.8)

        # Compute the output of the EncodingLayer
        out = enc(x, video_mask)

        # Check that the output has the expected shape
        self.assertEqual(out.shape, (2, 10, 512))

if __name__ == '__main__':
    unittest.main()
