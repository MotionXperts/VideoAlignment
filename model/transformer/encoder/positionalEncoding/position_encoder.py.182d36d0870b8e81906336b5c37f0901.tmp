import torch
import torch.nn as nn
import numpy as np


class PositionalEncoder(nn.Module):
    def __init__(self,cfg,embed_size,dout_p):
        super(PositionalEncoder,self).__init__()
        self.cfg=cfg
        self.embed_size=embed_size                        # dimension of the input/output embedding space e.g.: if the input is (T x 256), T is the seqence length and 256 is the embedding space (512)
        self.dropout = nn.Dropout(dout_p)  
        if self.cfg:         
            self.seq_len = self.cfg.DATA.SEQ_LEN

    def encode(self,seq_len,embed_size,train_len=None):
        # construct all the odds entries
        odds = np.arange(0,embed_size,2)  ## [0 , 2 , 4 , .... , d_model ]    (if d_model is odd) 
        evens = np.arange(1,embed_size,2) ## [1 , 3 , 5 , .... , d_model-1]   (if d_model is odd)
        
        # construct multiple positional encoding since transformer operates parrellally
        pos_enc_mat = np.zeros((seq_len,embed_size)) ## Shape: (seq_len , d_model)

        pos_list = np.arange(seq_len) ## [0 , 1 , 2 , 3 , 4 , .... , seq_len-1]
        for i,pos in enumerate((pos_list)):
            pos_enc_mat[i, odds]  = np.sin(pos / (10000 ** (odds / embed_size))) 
            pos_enc_mat[i, evens] = np.cos(pos / (10000 ** (evens / embed_size)))

        return torch.from_numpy(pos_enc_mat).unsqueeze(0) # unsqueeze add another dimension here (seq_len,d_model) -> (1,seq_len,d_model)
    
    def forward(self,x):
        _,T,embed_size = x.shape #(1,T,256)
        pos_enc_matrix = self.encodes(T,embed_size) #(1,T,256)
        x = x + pos_enc_matrix.type_as(x)

        x = self.dropout(x)
        return x

if __name__ == "__main__":
    import matplotlib.pyplot as plt

    PE = PositionalEncoder(None,10,0.8)
    p = PE.encode(seq_len=100,d_model=512)
    p = p.reshape(100,512)
    cax = plt.matshow(p)
    plt.savefig('pe.png')