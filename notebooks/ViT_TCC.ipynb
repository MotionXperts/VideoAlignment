{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import CvtModel,CvtConfig\n",
    "\n",
    "configuration = CvtConfig(cls_token=[False,False,False],depth=[1,4,16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/cvt-21 were not used when initializing CvtModel: ['layernorm.bias', 'classifier.weight', 'classifier.bias', 'layernorm.weight', 'cvt.encoder.stages.2.cls_token']\n",
      "- This IS expected if you are initializing CvtModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CvtModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CvtConfig {\n",
      "  \"_name_or_path\": \"microsoft/cvt-21\",\n",
      "  \"attention_drop_rate\": [\n",
      "    0.0,\n",
      "    0.0,\n",
      "    0.0\n",
      "  ],\n",
      "  \"cls_token\": [\n",
      "    false,\n",
      "    false,\n",
      "    false\n",
      "  ],\n",
      "  \"depth\": [\n",
      "    1,\n",
      "    4,\n",
      "    16\n",
      "  ],\n",
      "  \"drop_path_rate\": [\n",
      "    0.0,\n",
      "    0.0,\n",
      "    0.1\n",
      "  ],\n",
      "  \"drop_rate\": [\n",
      "    0.0,\n",
      "    0.0,\n",
      "    0.0\n",
      "  ],\n",
      "  \"embed_dim\": [\n",
      "    64,\n",
      "    192,\n",
      "    384\n",
      "  ],\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"kernel_qkv\": [\n",
      "    3,\n",
      "    3,\n",
      "    3\n",
      "  ],\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"mlp_ratio\": [\n",
      "    4.0,\n",
      "    4.0,\n",
      "    4.0\n",
      "  ],\n",
      "  \"model_type\": \"cvt\",\n",
      "  \"num_channels\": 3,\n",
      "  \"num_heads\": [\n",
      "    1,\n",
      "    3,\n",
      "    6\n",
      "  ],\n",
      "  \"padding_kv\": [\n",
      "    1,\n",
      "    1,\n",
      "    1\n",
      "  ],\n",
      "  \"padding_q\": [\n",
      "    1,\n",
      "    1,\n",
      "    1\n",
      "  ],\n",
      "  \"patch_padding\": [\n",
      "    2,\n",
      "    1,\n",
      "    1\n",
      "  ],\n",
      "  \"patch_sizes\": [\n",
      "    7,\n",
      "    3,\n",
      "    3\n",
      "  ],\n",
      "  \"patch_stride\": [\n",
      "    4,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"qkv_bias\": [\n",
      "    true,\n",
      "    true,\n",
      "    true\n",
      "  ],\n",
      "  \"qkv_projection_method\": [\n",
      "    \"dw_bn\",\n",
      "    \"dw_bn\",\n",
      "    \"dw_bn\"\n",
      "  ],\n",
      "  \"stride_kv\": [\n",
      "    2,\n",
      "    2,\n",
      "    2\n",
      "  ],\n",
      "  \"stride_q\": [\n",
      "    1,\n",
      "    1,\n",
      "    1\n",
      "  ],\n",
      "  \"transformers_version\": \"4.30.2\"\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ViT = CvtModel.from_pretrained(\"microsoft/cvt-21\",config=configuration,ignore_mismatched_sizes=True)\n",
    "print(ViT.config)\n",
    "len(list(ViT.encoder.stages[2].children())[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11, 224, 224, 3])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchvision.io import read_video\n",
    "vid,_,_ = read_video(\"/home/c1l1mo/datasets/NACL/1_jumps/1_jump_videos/467204328706015300_0.mp4\",pts_unit=\"sec\")\n",
    "vid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vid = vid.permute(0,3,1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11, 3, 224, 224])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 224, 224])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(vid.shape)\n",
    "frame = vid[0]\n",
    "frame.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading (…)rocessor_config.json: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 266/266 [00:00<00:00, 109kB/s]\n",
      "Could not find image processor class in the image processor config or the model config. Loading based on pattern matching with the model's feature extractor configuration.\n",
      "2023-11-28 17:19:58.735381: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoImageProcessor\n",
    "image_processor = AutoImageProcessor.from_pretrained(\"microsoft/cvt-13\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 224, 224])\n"
     ]
    }
   ],
   "source": [
    "print(frame.shape)\n",
    "processed_frame = image_processor(vid,return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11, 3, 224, 224])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipt = processed_frame['pixel_values']\n",
    "ipt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = ViT(ipt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CvtEncoder(\n",
       "  (stages): ModuleList(\n",
       "    (0): CvtStage(\n",
       "      (embedding): CvtEmbeddings(\n",
       "        (convolution_embeddings): CvtConvEmbeddings(\n",
       "          (projection): Conv2d(3, 64, kernel_size=(7, 7), stride=(4, 4), padding=(2, 2))\n",
       "          (normalization): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (layers): Sequential(\n",
       "        (0): CvtLayer(\n",
       "          (attention): CvtAttention(\n",
       "            (attention): CvtSelfAttention(\n",
       "              (convolution_projection_query): CvtSelfAttentionProjection(\n",
       "                (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                  (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)\n",
       "                  (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "                (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "              )\n",
       "              (convolution_projection_key): CvtSelfAttentionProjection(\n",
       "                (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                  (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
       "                  (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "                (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "              )\n",
       "              (convolution_projection_value): CvtSelfAttentionProjection(\n",
       "                (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                  (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
       "                  (normalization): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "                (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "              )\n",
       "              (projection_query): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (projection_key): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (projection_value): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): CvtSelfOutput(\n",
       "              (dense): Linear(in_features=64, out_features=64, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): CvtIntermediate(\n",
       "            (dense): Linear(in_features=64, out_features=256, bias=True)\n",
       "            (activation): GELU(approximate=none)\n",
       "          )\n",
       "          (output): CvtOutput(\n",
       "            (dense): Linear(in_features=256, out_features=64, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (layernorm_before): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): CvtStage(\n",
       "      (embedding): CvtEmbeddings(\n",
       "        (convolution_embeddings): CvtConvEmbeddings(\n",
       "          (projection): Conv2d(64, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (normalization): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (layers): Sequential(\n",
       "        (0): CvtLayer(\n",
       "          (attention): CvtAttention(\n",
       "            (attention): CvtSelfAttention(\n",
       "              (convolution_projection_query): CvtSelfAttentionProjection(\n",
       "                (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                  (convolution): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "                  (normalization): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "                (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "              )\n",
       "              (convolution_projection_key): CvtSelfAttentionProjection(\n",
       "                (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                  (convolution): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "                  (normalization): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "                (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "              )\n",
       "              (convolution_projection_value): CvtSelfAttentionProjection(\n",
       "                (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                  (convolution): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "                  (normalization): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "                (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "              )\n",
       "              (projection_query): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (projection_key): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (projection_value): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): CvtSelfOutput(\n",
       "              (dense): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): CvtIntermediate(\n",
       "            (dense): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (activation): GELU(approximate=none)\n",
       "          )\n",
       "          (output): CvtOutput(\n",
       "            (dense): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (layernorm_before): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): CvtLayer(\n",
       "          (attention): CvtAttention(\n",
       "            (attention): CvtSelfAttention(\n",
       "              (convolution_projection_query): CvtSelfAttentionProjection(\n",
       "                (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                  (convolution): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "                  (normalization): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "                (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "              )\n",
       "              (convolution_projection_key): CvtSelfAttentionProjection(\n",
       "                (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                  (convolution): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "                  (normalization): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "                (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "              )\n",
       "              (convolution_projection_value): CvtSelfAttentionProjection(\n",
       "                (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                  (convolution): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "                  (normalization): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "                (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "              )\n",
       "              (projection_query): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (projection_key): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (projection_value): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): CvtSelfOutput(\n",
       "              (dense): Linear(in_features=192, out_features=192, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): CvtIntermediate(\n",
       "            (dense): Linear(in_features=192, out_features=768, bias=True)\n",
       "            (activation): GELU(approximate=none)\n",
       "          )\n",
       "          (output): CvtOutput(\n",
       "            (dense): Linear(in_features=768, out_features=192, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): Identity()\n",
       "          (layernorm_before): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): CvtStage(\n",
       "      (embedding): CvtEmbeddings(\n",
       "        (convolution_embeddings): CvtConvEmbeddings(\n",
       "          (projection): Conv2d(192, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (normalization): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (layers): Sequential(\n",
       "        (0): CvtLayer(\n",
       "          (attention): CvtAttention(\n",
       "            (attention): CvtSelfAttention(\n",
       "              (convolution_projection_query): CvtSelfAttentionProjection(\n",
       "                (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                  (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "                  (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "                (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "              )\n",
       "              (convolution_projection_key): CvtSelfAttentionProjection(\n",
       "                (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                  (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                  (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "                (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "              )\n",
       "              (convolution_projection_value): CvtSelfAttentionProjection(\n",
       "                (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                  (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                  (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "                (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "              )\n",
       "              (projection_query): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (projection_key): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (projection_value): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): CvtSelfOutput(\n",
       "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): CvtIntermediate(\n",
       "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (activation): GELU(approximate=none)\n",
       "          )\n",
       "          (output): CvtOutput(\n",
       "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): CvtDropPath(p=0.02222222276031971)\n",
       "          (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): CvtLayer(\n",
       "          (attention): CvtAttention(\n",
       "            (attention): CvtSelfAttention(\n",
       "              (convolution_projection_query): CvtSelfAttentionProjection(\n",
       "                (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                  (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "                  (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "                (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "              )\n",
       "              (convolution_projection_key): CvtSelfAttentionProjection(\n",
       "                (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                  (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                  (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "                (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "              )\n",
       "              (convolution_projection_value): CvtSelfAttentionProjection(\n",
       "                (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                  (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                  (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "                (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "              )\n",
       "              (projection_query): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (projection_key): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (projection_value): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): CvtSelfOutput(\n",
       "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): CvtIntermediate(\n",
       "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (activation): GELU(approximate=none)\n",
       "          )\n",
       "          (output): CvtOutput(\n",
       "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): CvtDropPath(p=0.02222222276031971)\n",
       "          (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): CvtLayer(\n",
       "          (attention): CvtAttention(\n",
       "            (attention): CvtSelfAttention(\n",
       "              (convolution_projection_query): CvtSelfAttentionProjection(\n",
       "                (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                  (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "                  (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "                (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "              )\n",
       "              (convolution_projection_key): CvtSelfAttentionProjection(\n",
       "                (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                  (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                  (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "                (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "              )\n",
       "              (convolution_projection_value): CvtSelfAttentionProjection(\n",
       "                (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                  (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                  (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "                (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "              )\n",
       "              (projection_query): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (projection_key): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (projection_value): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): CvtSelfOutput(\n",
       "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): CvtIntermediate(\n",
       "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (activation): GELU(approximate=none)\n",
       "          )\n",
       "          (output): CvtOutput(\n",
       "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): CvtDropPath(p=0.02222222276031971)\n",
       "          (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): CvtLayer(\n",
       "          (attention): CvtAttention(\n",
       "            (attention): CvtSelfAttention(\n",
       "              (convolution_projection_query): CvtSelfAttentionProjection(\n",
       "                (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                  (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "                  (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "                (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "              )\n",
       "              (convolution_projection_key): CvtSelfAttentionProjection(\n",
       "                (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                  (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                  (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "                (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "              )\n",
       "              (convolution_projection_value): CvtSelfAttentionProjection(\n",
       "                (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                  (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                  (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "                (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "              )\n",
       "              (projection_query): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (projection_key): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (projection_value): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): CvtSelfOutput(\n",
       "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): CvtIntermediate(\n",
       "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (activation): GELU(approximate=none)\n",
       "          )\n",
       "          (output): CvtOutput(\n",
       "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): CvtDropPath(p=0.02222222276031971)\n",
       "          (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (4): CvtLayer(\n",
       "          (attention): CvtAttention(\n",
       "            (attention): CvtSelfAttention(\n",
       "              (convolution_projection_query): CvtSelfAttentionProjection(\n",
       "                (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                  (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "                  (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "                (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "              )\n",
       "              (convolution_projection_key): CvtSelfAttentionProjection(\n",
       "                (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                  (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                  (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "                (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "              )\n",
       "              (convolution_projection_value): CvtSelfAttentionProjection(\n",
       "                (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                  (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                  (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "                (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "              )\n",
       "              (projection_query): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (projection_key): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (projection_value): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): CvtSelfOutput(\n",
       "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): CvtIntermediate(\n",
       "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (activation): GELU(approximate=none)\n",
       "          )\n",
       "          (output): CvtOutput(\n",
       "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): CvtDropPath(p=0.02222222276031971)\n",
       "          (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (5): CvtLayer(\n",
       "          (attention): CvtAttention(\n",
       "            (attention): CvtSelfAttention(\n",
       "              (convolution_projection_query): CvtSelfAttentionProjection(\n",
       "                (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                  (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "                  (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "                (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "              )\n",
       "              (convolution_projection_key): CvtSelfAttentionProjection(\n",
       "                (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                  (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                  (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "                (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "              )\n",
       "              (convolution_projection_value): CvtSelfAttentionProjection(\n",
       "                (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                  (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                  (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "                (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "              )\n",
       "              (projection_query): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (projection_key): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (projection_value): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): CvtSelfOutput(\n",
       "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): CvtIntermediate(\n",
       "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (activation): GELU(approximate=none)\n",
       "          )\n",
       "          (output): CvtOutput(\n",
       "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): CvtDropPath(p=0.02222222276031971)\n",
       "          (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (6): CvtLayer(\n",
       "          (attention): CvtAttention(\n",
       "            (attention): CvtSelfAttention(\n",
       "              (convolution_projection_query): CvtSelfAttentionProjection(\n",
       "                (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                  (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "                  (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "                (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "              )\n",
       "              (convolution_projection_key): CvtSelfAttentionProjection(\n",
       "                (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                  (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                  (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "                (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "              )\n",
       "              (convolution_projection_value): CvtSelfAttentionProjection(\n",
       "                (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                  (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                  (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "                (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "              )\n",
       "              (projection_query): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (projection_key): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (projection_value): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): CvtSelfOutput(\n",
       "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): CvtIntermediate(\n",
       "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (activation): GELU(approximate=none)\n",
       "          )\n",
       "          (output): CvtOutput(\n",
       "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): CvtDropPath(p=0.02222222276031971)\n",
       "          (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (7): CvtLayer(\n",
       "          (attention): CvtAttention(\n",
       "            (attention): CvtSelfAttention(\n",
       "              (convolution_projection_query): CvtSelfAttentionProjection(\n",
       "                (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                  (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "                  (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "                (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "              )\n",
       "              (convolution_projection_key): CvtSelfAttentionProjection(\n",
       "                (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                  (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                  (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "                (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "              )\n",
       "              (convolution_projection_value): CvtSelfAttentionProjection(\n",
       "                (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                  (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                  (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "                (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "              )\n",
       "              (projection_query): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (projection_key): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (projection_value): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): CvtSelfOutput(\n",
       "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): CvtIntermediate(\n",
       "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (activation): GELU(approximate=none)\n",
       "          )\n",
       "          (output): CvtOutput(\n",
       "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): CvtDropPath(p=0.02222222276031971)\n",
       "          (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (8): CvtLayer(\n",
       "          (attention): CvtAttention(\n",
       "            (attention): CvtSelfAttention(\n",
       "              (convolution_projection_query): CvtSelfAttentionProjection(\n",
       "                (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                  (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "                  (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "                (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "              )\n",
       "              (convolution_projection_key): CvtSelfAttentionProjection(\n",
       "                (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                  (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                  (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "                (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "              )\n",
       "              (convolution_projection_value): CvtSelfAttentionProjection(\n",
       "                (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                  (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                  (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "                (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "              )\n",
       "              (projection_query): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (projection_key): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (projection_value): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): CvtSelfOutput(\n",
       "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): CvtIntermediate(\n",
       "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (activation): GELU(approximate=none)\n",
       "          )\n",
       "          (output): CvtOutput(\n",
       "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): CvtDropPath(p=0.02222222276031971)\n",
       "          (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (9): CvtLayer(\n",
       "          (attention): CvtAttention(\n",
       "            (attention): CvtSelfAttention(\n",
       "              (convolution_projection_query): CvtSelfAttentionProjection(\n",
       "                (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                  (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "                  (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "                (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "              )\n",
       "              (convolution_projection_key): CvtSelfAttentionProjection(\n",
       "                (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                  (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                  (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "                (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "              )\n",
       "              (convolution_projection_value): CvtSelfAttentionProjection(\n",
       "                (convolution_projection): CvtSelfAttentionConvProjection(\n",
       "                  (convolution): Conv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=384, bias=False)\n",
       "                  (normalization): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "                )\n",
       "                (linear_projection): CvtSelfAttentionLinearProjection()\n",
       "              )\n",
       "              (projection_query): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (projection_key): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (projection_value): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (output): CvtSelfOutput(\n",
       "              (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): CvtIntermediate(\n",
       "            (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "            (activation): GELU(approximate=none)\n",
       "          )\n",
       "          (output): CvtOutput(\n",
       "            (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "            (dropout): Dropout(p=0.0, inplace=False)\n",
       "          )\n",
       "          (drop_path): CvtDropPath(p=0.02222222276031971)\n",
       "          (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "          (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ViT.encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11, 384, 14, 14])\n"
     ]
    }
   ],
   "source": [
    "print(outputs.last_hidden_state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "backbone = nn.Sequential((list(ViT.children())[0]).stages[0],(list(ViT.children())[0]).stages[1],(list((list(ViT.children())[0]).stages[2].children())[0]))\n",
    "finetune = (list((list(ViT.children())[0]).stages[2].children())[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([11, 384, 14, 14])\n"
     ]
    }
   ],
   "source": [
    "backbone.eval()\n",
    "finetune.eval()\n",
    "with torch.no_grad():\n",
    "    hidden_state,cls_token = (list(ViT.children())[0]).stages[0](ipt)\n",
    "    hidden_state,cls_token = (list(ViT.children())[0]).stages[1](hidden_state)\n",
    "    hidden_state = (list((list(ViT.children())[0]).stages[2].children())[0])(hidden_state)\n",
    "    batch_size, num_channels, height, width = hidden_state.shape\n",
    "    # rearrange b c h w -> b (h w) c\"\n",
    "    hidden_state = hidden_state.view(batch_size, num_channels, height * width).permute(0, 2, 1)\n",
    "    for layer in finetune:\n",
    "        hidden_state = layer(hidden_state,height,width)\n",
    "    hidden_state = hidden_state.permute(0, 2, 1).view(batch_size, num_channels, height, width)\n",
    "    print(hidden_state.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert model to onnx\n",
    "from torch.onnx import TrainingMode\n",
    "model = CvtModel.from_pretrained(\"microsoft/cvt-21\")\n",
    "model = model.eval()\n",
    "dummy_input = torch.rand(40,3,224,224)\n",
    "input_names = [\"input\"]\n",
    "output_names = [\"output\"]\n",
    "\n",
    "# torch.onnx.export(model,dummy_input,\"CVT_train.onnx\",verbose=False,input_names=input_names,output_names=output_names,export_params=True,training=TrainingMode.TRAINING,opset_version=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "carl",
   "language": "python",
   "name": "carl"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
